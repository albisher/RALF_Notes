# Idea: Fast Raw Output Integration into OOP Pipeline

## 1. Current Codebase Overview

### 1.1. What We Got (Core OOP Structure & Components)

The project is structured around a modular, object-oriented design, with each component ("box") having a single responsibility.

*   **`main.py`**:
    *   **What it does:** Serves as the primary entry point for the OOP application. Orchestrates the document generation process.
    *   **Key components:** Imports and wires together the various boxes to form the complete pipeline. Contains the main execution loop.
*   **`config.py`**:
    *   **What it does:** Centralized configuration file. Defines global parameters such as `SOURCE_PATHS`, `TARGET_DIR`, `MODEL_NAME`, Ollama `OPTIONS`, and caching settings (`ENABLE_CACHING`, `CACHE_TTL_DAYS`, etc.).
*   **`prompts.py`**:
    *   **What it does:** Stores all AI prompt templates and system prompts used for interacting with the Ollama model.
*   **`models/` directory**: Houses data structures (dataclasses) used throughout the application.
    *   **`models/document.py`**: Defines `Document`, `DocumentMetadata`, and `DocumentSections` dataclasses for structuring the generated Obsidian notes.
    *   **`models/section.py`**: Defines a generic `Section` dataclass (though not extensively used in the current generation flow).
    *   **`models/generation_options.py`**: Defines `GenerationOptions` dataclass (currently unused).
*   **`validators/` directory**: Contains classes responsible for validating content generated by the AI model.
    *   **`validators/base_validator.py`**: Defines the `BaseValidator` abstract interface, ensuring all validators have a `validate` method.
    *   **`validators/summary_validator.py`**: Validates the format and content of generated summaries.
    *   **`validators/tags_validator.py`**: Validates the format of generated tags.
    *   **`validators/structure_validator.py`**: Validates the overall markdown structure of the final document.
    *   **`validators/general_validator.py`**: Provides generic validation checks (e.g., detecting conversational filler or questions).
*   **`cleaners/` directory**: Contains classes for cleaning and formatting AI-generated text.
    *   **`cleaners/base_cleaner.py`**: Defines the `BaseCleaner` abstract interface.
    *   **`cleaners/summary_cleaner.py`**: Cleans raw summary text (e.g., removes code fences, dates).
    *   **`cleaners/tags_cleaner.py`**: Cleans and formats tags into the desired `#tag` format.
    *   **`cleaners/details_cleaner.py`**: Aggressively cleans details content (e.g., removes frontmatter, headers, ensures callout formatting).
    *   **`cleaners/general_cleaner.py`**: Provides specific cleaning methods for various content types (e.g., `clean_not_applicable`, `clean_mermaid`, `clean_doc_type`, `clean_related`). Its generic `clean` method is a no-op fallback.
*   **`generators/` directory**: Contains classes that encapsulate the logic for generating specific sections of the Obsidian note using the Ollama model.
    *   **`generators/base_section_generator.py`**: Defines the `BaseSectionGenerator` abstract interface. Handles caching, validation, and regeneration retry logic common to all section generators.
    *   **`generators/section_generator.py`**: A generic implementation of `BaseSectionGenerator` for simple text sections.
    *   **`generators/summary_generator.py`**: Generates the summary section, including dynamic length calculation.
    *   **`generators/details_generator.py`**: Generates the details section.
    *   **`generators/tags_generator.py`**: Generates tags, including dynamic count calculation.
    *   **`generators/key_functions_generator.py`**: Generates key functions/classes section.
    *   **`generators/usage_generator.py`**: Generates usage examples section.
    *   **`generators/related_generator.py`**: Generates related links section, including dynamic count calculation.
    *   **`generators/dependency_graph_generator.py`**: Generates Mermaid dependency graphs.
    *   **`generators/security_risks_generator.py`**: Generates security risks section.
    *   **`generators/doc_type_generator.py`**: Generates the document type.
*   **`utils/` directory**: General utility functions and classes.
    *   **`utils/file_processor.py`**: Handles file system operations (reading files, getting all files in a path).
    *   **`utils/token_estimator.py`**: Provides a static method to estimate token count.
    *   **`utils/logger_factory.py`**: Configures and provides logger instances.
    *   **`utils/retry_manager.py`**: (Currently unused helper for retry logic).
*   **`cache/` directory**: Manages the caching mechanism for model responses.
    *   **`cache/cache_manager.py`**: Functions for managing the cache (e.g., `get_cached_response`, `cache_response`, `clear_cache`, `get_cache_stats`).
*   **`core/` directory**: Core components for the application logic.
    *   **`core/ollama_client.py`**: Wraps the Ollama API client, providing methods for model interaction (`generate`, `list_models`, `model_exists`).
    *   **`core/document_generator.py`**: The main orchestrator for generating a complete `Document` object by invoking the various `SectionGenerator`s.
    *   **`core/section_manager.py`**: (Currently an empty placeholder module, intended for future advanced section management).
*   **`core/old/RalfNotes.py`**:
    *   **What it does:** This is a monolithic, standalone script that directly reads code files, makes model calls for analysis (summarization, JSON extraction), formats the result into Obsidian markdown, and saves it to a target directory. It includes its own CLI via `typer`.
    *   **How we need it to be:** This file should remain completely untouched and will *not* be integrated into the new OOP pipeline as a component or dependency. It serves purely as a reference or an alternative standalone tool.

### 1.2. How the OOP Project Works (`main.py`'s current behavior)
The `main.py` script executes the following high-level flow:
1.  Sets up logging.
2.  Initializes a `DocumentGenerator` instance, injecting all necessary dependencies (Ollama client, file processor, token estimator, and all specific `SectionGenerator`s, which in turn are configured with their respective `validators` and `cleaners`).
3.  Discovers source files from `SOURCE_PATHS`.
4.  For each discovered `file_path`:
    *   Calls `DocumentGenerator.generate(file_path)` to produce a `Document` object.
    *   Converts the `Document` object to markdown using `doc.to_markdown()`.
    *   Saves the resulting markdown to `TARGET_DIR`.
5.  CLI arguments (`--clear-cache`, `--cache-stats`) allow basic cache management outside the main generation flow.
6.  Caching (`cache_manager.py`) is integrated within `BaseSectionGenerator` to store and retrieve model responses, reducing redundant model calls.

## 2. Proposed Integration: "Fast Raw Output" Pipeline (within OOP Project)

### 2.1. Goal
The primary goal is to empower the existing OOP project to generate a "raw" model output efficiently, similar to the monolithic `RalfNotes.py`'s single-pass approach, but *entirely within its modular architecture*. This raw output will then be refined by other OOP components, *without* the refinement stages making additional model calls. This maintains the "boxes" methodology, avoids compromising existing work, and uses minimal corrections.

### 2.2. New Workflow Diagram (Conceptual)
```
Source File
      |
      V
OOP Main.py (triggered with '--raw-gen' option)
      |
      V
OOP RawContentGenerator (NEW: initial model call for raw markdown)
      |
      V
Raw Markdown Output (saved to TEMP_RAW_OUTPUT_DIR)
      |
      V
OOP Main.py (Internal loop continues, or separate command for post-processing)
      |
      V
core/raw_document_parser.py (reads & parses raw markdown from TEMP_RAW_OUTPUT_DIR)
      |
      V
DocumentMetadata & DocumentSections Objects
      |
      V
core/document_post_processor.py (applies OOP validators/cleaners)
      |
      V
Final Document Object
      |
      V
Final Obsidian Note (saved to TARGET_DIR)
```

## 3. Detailed Plan for Integration

### 3.1. Phase 1: Raw Content Generator (New OOP Component)
*   **Action:** Create a new component, `core/raw_content_generator.py`, with a `RawContentGenerator` class.
*   **Purpose:** This class will encapsulate the logic to perform a single, initial model call using the `OllamaClient` to generate a comprehensive "raw" markdown output for a given source file, mimicking the initial output style of `RalfNotes.py`. It will leverage existing `TokenEstimator` and `FileProcessor`.
*   **Key Methods:**
    *   `__init__(self, ollama_client, token_estimator, file_processor)`
    *   `generate_raw_markdown(self, file_path: Path) -> str`: Reads `file_path`, prepares a prompt for a comprehensive overview, makes an `OllamaClient` call, extracts relevant markdown, and returns it.
*   **Output Location:** The output of this component will be saved to `TEMP_RAW_OUTPUT_DIR`.
*   **Model Calls:** This new OOP component will perform the initial model call.

### 3.2. Phase 2: Adapting OOP `main.py` (Orchestration & CLI)
*   **Action:** Modify `main.py` to orchestrate this new "fast raw output" pipeline.
*   **New CLI Option:** Introduce a new `typer` option (e.g., `--raw-gen`) to the `generate` command in `main.py`.
*   **Logic when `--raw-gen` is active:**
    1.  If `TEMP_RAW_OUTPUT_DIR` does not exist, create it.
    2.  Instantiate `RawContentGenerator`.
    3.  Discover source files (using `FileProcessor.get_all_files(SOURCE_PATHS)`).
    4.  For each source file:
        *   Call `RawContentGenerator.generate_raw_markdown(file_path)` to get the raw markdown.
        *   Save this raw markdown to `TEMP_RAW_OUTPUT_DIR` (e.g., `temp_raw_output/original_filename.md`).
        *   Then, proceed to process these newly generated raw files:
            *   Instantiate `RawDocumentParser` with the path to the raw markdown file in `TEMP_RAW_OUTPUT_DIR`.
            *   Use `RawDocumentParser.parse()` to extract `DocumentMetadata` and `DocumentSections`.
            *   Instantiate `DocumentPostProcessor` with this parsed data and the original file's stem.
            *   Call `DocumentPostProcessor.post_process()` to get the final `Document` object.
            *   Save the `Document.to_markdown()` to the `TARGET_DIR`.
*   **Logic when `--raw-gen` is NOT active:** The current direct `DocumentGenerator` flow should remain for generating full documents directly.

### 3.3. Phase 3: `RawDocumentParser` Implementation (Initial creation and refinement)
*   **Purpose:** The `RawDocumentParser` (in `core/raw_document_parser.py`) will be responsible for taking the markdown output generated by the *new OOP RawContentGenerator* and converting it into `DocumentMetadata` and `DocumentSections` objects.
*   **Key Methods:** (As previously defined, but now targeting the output style of `RawContentGenerator`).
    *   `__init__(self, file_path: Path)`
    *   `_read_file(self) -> str`
    *   `_extract_frontmatter(self, text: str) -> Tuple[str, str]`
    *   `_parse_frontmatter(self, frontmatter_str: str) -> DocumentMetadata`
    *   `_parse_sections(self, content_str: str) -> DocumentSections`
*   **Considerations:** Needs to be robust to variations in the `RawContentGenerator`'s markdown output.

### 3.4. Phase 4: `DocumentPostProcessor` Implementation (Initial creation and refinement)
*   **Purpose:** The `DocumentPostProcessor` (in `core/document_post_processor.py`) will take the parsed `DocumentMetadata` and `DocumentSections` from `RawDocumentParser` and apply the full suite of OOP project's validators and cleaners to ensure the final output quality.
*   **Key Methods:** (As previously defined).
    *   `__init__(self, metadata: DocumentMetadata, sections: DocumentSections, file_name: str)`
    *   `post_process(self) -> Document`
    *   `_final_clean(self, doc_md: str) -> str`
*   **Dependencies:** Will need access to the various `validators/*` and `cleaners/*` boxes.

### 3.5. Phase 5: Configuration Updates
*   **Action:** Define `TEMP_RAW_OUTPUT_DIR = './temp_raw_output'` in `config.py`.

### 3.6. Phase 6: Refinement and Cleanup
*   **Action:** Ensure that when `--raw-gen` is active, the conventional `DocumentGenerator`'s model-calling paths are bypassed. The overall system should clearly differentiate between direct generation and processing of internally-generated raw output.
*   **Testing:** Outline a testing strategy for this new pipeline, focusing on the raw generation step and subsequent parsing/post-processing.

## 4. Conclusion
This revised approach ensures `RalfNotes.py` remains truly untouched. The OOP project gains the ability to generate a fast, raw model output internally and then refine it using its modular components. This maintains the "boxes" methodology, avoids compromising existing work, and uses minimal, targeted additions to achieve the goal.

## 5. Next Steps
*   Implement `TEMP_RAW_OUTPUT_DIR` in `config.py`.
*   Create `core/raw_content_generator.py` and its `RawContentGenerator` class.
*   Implement `core/raw_document_parser.py` and its `RawDocumentParser` class.
*   Implement `core/document_post_processor.py` and its `DocumentPostProcessor` class.
*   Modify `main.py` to orchestrate this new pipeline with the `--raw-gen` option.