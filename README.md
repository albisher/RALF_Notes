# RALF Note v2.0

**Recursive AI-powered Learning Framework for Obsidian Documentation**

[![License](https://img.shields.io/badge/License-Custom-blue.svg)](LICENSE)
[![Python](https://img.shields.io/badge/Python-3.9+-green.svg)](https://www.python.org/)
[![Ollama](https://img.shields.io/badge/Ollama-Required-orange.svg)](https://ollama.ai/)

AI-powered documentation generator that transforms your code into beautiful Obsidian notes with a single command.

---

## âœ¨ Features

- ğŸš€ **Single LLM Call** - 9x faster than multi-generator approach
- ğŸ¨ **Beautiful TUI** - Colored output, progress bars, ASCII art
- ğŸ“¦ **Unified JSON** - One structured response, deterministic formatting
- ğŸ—ï¸ **Clean Architecture** - Boxes methodology, OOP, dependency injection
- ğŸ’» **Professional CLI** - Typer-powered with intuitive commands
- ğŸ“Š **Real-time Progress** - See exactly what's happening
- ğŸ”„ **Batch Processing** - Process entire codebases at once
- ğŸ¯ **Smart Validation** - Auto-fixes common issues

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.9+
- [Ollama](https://ollama.ai/) installed and running
- Model: `ollama pull ministral-3:3b`

### Installation

```bash
# Clone the repository
git clone https://github.com/albisher/RALF_Notes.git
cd RALF_Notes

# Install dependencies
pip install typer rich ollama

# Test connection
python ralf.py test

# Generate documentation
python ralf.py generate
```

That's it! Your documentation will be in `to_obsidian/`

---

## ğŸ“– Usage

### Basic Commands

```bash
# Generate documentation for default paths
python ralf.py generate

# Generate for specific path
python ralf.py generate /path/to/code

# Custom output directory
python ralf.py generate --output /custom/output

# Dry run (preview)
python ralf.py generate --dry-run

# Overwrite existing docs
python ralf.py generate --overwrite

# Quiet mode (minimal output)
python ralf.py generate --quiet

# Use different model
python ralf.py generate --model qwen2.5:14b
```

### Other Commands

```bash
# Check configuration
python ralf.py status

# Test Ollama connection
python ralf.py test

# Show version
python ralf.py version

# Get help
python ralf.py --help
```

---

## ğŸ¨ Beautiful Output

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—   â•‘
â•‘   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•”â•â•â•â•â•    â–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—  â•‘
â•‘   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—      â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘  â•‘
â•‘   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•”â•â•â•      â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘  â•‘
â•‘   â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘         â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â„¹ï¸  Model: ministral-3:3b
â„¹ï¸  Target: to_obsidian/
â„¹ï¸  Found 100 files to process
ğŸ“„  Analyzing: main.py
âœ…  Generated: main.md
...
Processing files â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 100% â€¢ 0:02:10 â€¢ 0:00:00

â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ“Š Results â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Total Files: 100                 â”‚
â”‚ âœ… Success: 95                   â”‚
â”‚ âŒ Failed: 3                     â”‚
â”‚ Time: 125.4s                     â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
```

---

## âš™ï¸ Configuration

Edit `config.py` to customize:

```python
# Where to find your code
SOURCE_PATHS = [
    '/path/to/your/code/',
]

# Where to save documentation
TARGET_DIR = '/path/to/output/'

# Which model to use
MODEL_NAME = 'ministral-3:3b'

# Ollama server
OLLAMA_HOST = 'http://127.0.0.1:11434'
```

---

## ğŸ“Š Performance

| Metric | Value |
|--------|-------|
| **Processing Time** | ~14s per file |
| **LLM Calls** | 1 per file (9x reduction!) |
| **Batch 100 files** | ~23 minutes |
| **Code Complexity** | 58% less than V1 |

---

## ğŸ—ï¸ Architecture

RALF Note v2.0 uses a unified JSON approach:

```
File â†’ JSONGenerator â†’ JSONExtractor â†’ JSONValidator â†’ MarkdownFormatter â†’ Obsidian MD
         (1 LLM call)   (Parse JSON)    (Validate)      (Format)         (Beautiful!)
```

### Key Components

- **JSONGenerator** - Single LLM call for all sections
- **JSONExtractor** - Robust JSON parsing with fallbacks
- **JSONValidator** - Schema validation and auto-fixing
- **MarkdownFormatter** - Deterministic markdown generation
- **DocumentPipeline** - Orchestrates the flow
- **FileProcessor** - Batch processing with progress
- **TUI** - Beautiful terminal interface

All following **Boxes methodology** with clean OOP design.

---

## ğŸ“ Project Structure

```
RALF_Notes/
â”œâ”€â”€ core_v2/              # Core components
â”‚   â”œâ”€â”€ models.py         # Data models
â”‚   â”œâ”€â”€ json_generator.py # LLM interaction
â”‚   â”œâ”€â”€ json_extractor.py # JSON parsing
â”‚   â”œâ”€â”€ json_validator.py # Validation
â”‚   â”œâ”€â”€ markdown_formatter.py # Formatting
â”‚   â”œâ”€â”€ document_pipeline.py  # Orchestration
â”‚   â””â”€â”€ file_processor.py     # Batch processing
â”œâ”€â”€ tui/                  # Terminal UI
â”‚   â”œâ”€â”€ console.py        # Rich console
â”‚   â”œâ”€â”€ progress.py       # Progress bars
â”‚   â””â”€â”€ ascii_art.py      # ASCII banners
â”œâ”€â”€ roadmap/              # Implementation docs
â”œâ”€â”€ ralf.py               # Main CLI
â”œâ”€â”€ config.py             # Configuration
â””â”€â”€ LICENSE               # License terms
```

---

## ğŸ“ Output Format

Each generated file includes:

```markdown
---
tags: #python, #documentation, #automation
created: 2026-01-09
type: code-notes
---

# filename

## Summary
High-level purpose in 1-2 sentences

## Details
Detailed explanation of logic and architecture

## Key Functions
### `function_name`
Description with signature and return value

## Usage
How to use this code

## Dependencies
Required libraries and modules

## Related
- [[Related File 1]]
- [[Related File 2]]

> [!INFO]- Key Insight
> Important information highlighted in callouts
```

---

## ğŸ¯ What's New in V2?

| Feature | V1 | V2 |
|---------|----|----|
| **Architecture** | 9 generators | 1 unified pipeline |
| **LLM Calls** | 9 per file | 1 per file |
| **Code Lines** | ~1,437 | ~600 |
| **TUI** | None | Beautiful! |
| **Complexity** | High | Low |
| **Speed** | ~15s/file | ~14s/file |

---

## ğŸ’¡ Why RALF Note?

- âœ… **Save Time** - Automated documentation generation
- âœ… **Stay Organized** - Obsidian integration
- âœ… **Understand Code** - AI-powered analysis
- âœ… **Knowledge Base** - Build a searchable library
- âœ… **Local & Private** - Runs on your machine with Ollama

---

## ğŸ“š Documentation

- **Quick Start:** [QUICK_START_V2.md](QUICK_START_V2.md)
- **Implementation:** [V2_IMPLEMENTATION_COMPLETE.md](V2_IMPLEMENTATION_COMPLETE.md)
- **Roadmap:** [roadmap/README.md](roadmap/README.md)
- **Archive:** [ARCHIVE_SUMMARY.md](ARCHIVE_SUMMARY.md)

---

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

By contributing, you agree that your contributions will be licensed under the same terms as this project.

---

## ğŸ“„ License

**Personal Use:** FREE âœ…
**Team Use:** $1/month per user ğŸ’¼
**Enterprise:** Custom quote ğŸ¢

**Commercial forking/modification is NOT allowed.** See [LICENSE](LICENSE) for details.

### Quick Summary:
- âœ… **FREE for personal use** - Use, modify, learn
- ğŸ’° **Paid for teams** - $1/month/user for businesses
- ğŸš« **No commercial forks** - Can't create competing products
- ğŸ“§ **Contact for licensing:** [abalbisher@gmail.com](mailto:abalbisher@gmail.com)

---

## ğŸ› Troubleshooting

### "ModuleNotFoundError: No module named 'typer'"
```bash
pip install typer rich ollama
```

### "Failed to connect to Ollama"
```bash
# Start Ollama
ollama serve

# Pull model
ollama pull ministral-3:3b
```

### "JSON parsing failed"
This is normal! The fallback creates a warning document with debug info.

---

## ğŸ“§ Contact

**Author:** Abdulrahman Albisher
**Email:** [abalbisher@gmail.com](mailto:abalbisher@gmail.com)
**GitHub:** [https://github.com/albisher/RALF_Notes](https://github.com/albisher/RALF_Notes)

---

## â­ Support

If you find RALF Note useful:
- â­ Star the repository
- ğŸ“¢ Share with others
- ğŸ› Report bugs
- ğŸ’¡ Suggest features
- ğŸ’° Purchase a license if using commercially

---

## ğŸ™ Acknowledgments

Built with:
- [Ollama](https://ollama.ai/) - Local LLM inference
- [Rich](https://github.com/Textualize/rich) - Terminal formatting
- [Typer](https://github.com/tiangolo/typer) - CLI framework

---

**RALF Note v2.0 - Transforming code into knowledge, one file at a time.** ğŸ“šâœ¨
